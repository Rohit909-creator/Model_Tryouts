{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d34204",
   "metadata": {},
   "source": [
    "# Qformer Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db14e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from qformer import QFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 32, 512))\n",
    "\n",
    "img = torch.randn((1,3,224,224))\n",
    "\n",
    "# Create an instance of the QFormer model with the following parameters:\n",
    "# - input_size: 512\n",
    "# - num_heads: 8\n",
    "# - num_layers: 8\n",
    "# - dropout: 0.1\n",
    "# - num_classes: 2\n",
    "# - num_patches: 2\n",
    "\n",
    "q_former = QFormer(512, 8, 8, 0.1, 2, 2)\n",
    "y = q_former(x, img)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432ab03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fafa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b482e53",
   "metadata": {},
   "source": [
    "# Surprise Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "663d81b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "tensor([[11.3411,  6.9629]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SurpriseMechanism(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_slots, slot_dim, learning_rate = 0.6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.slots = torch.randn((1, num_slots, slot_dim))\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, slot_dim)\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        proj = self.fc1(x)\n",
    "    \n",
    "        \n",
    "        surprise = nn.functional.mse_loss(self.slots, proj.expand_as(self.slots), reduction='none').sum(dim=-1)\n",
    "        \n",
    "        min_index = torch.argmin(surprise, dim=-1)\n",
    "        print(min_index)\n",
    "        \n",
    "        self.slots.data[0][min_index] = (1-self.lr)*self.slots.data[0][min_index] + self.lr*proj\n",
    "        \n",
    "        return surprise        \n",
    "        \n",
    "\n",
    "\n",
    "model = SurpriseMechanism(4,2,8)\n",
    "\n",
    "x_t = torch.randn((1, 4))\n",
    "\n",
    "out = model(x_t)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ac1909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.slots.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b578dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2288,  0.0145,  0.2790,  1.2779],\n",
       "         [ 1.9375, -0.7367, -2.1079, -0.0094]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slots = torch.randn((1, 2, 4))\n",
    "slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9001fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.expand_as(slots).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc3bf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1775,  1.4299,  0.2057, -0.6213]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d0d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1775,  1.4299,  0.2057, -0.6213],\n",
       "         [-0.1775,  1.4299,  0.2057, -0.6213]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.expand_as(slots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8901d2e",
   "metadata": {},
   "source": [
    "# HRM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd289c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 0\n",
      "at 4\n",
      "at 8\n",
      "at 12\n",
      "at 16\n",
      "at 20\n",
      "at 24\n",
      "at 28\n",
      "torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HRM(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, vocab_size, context_length, output_size, h_cycle = 4, l_cycle = 8, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h_cycle = h_cycle\n",
    "        self.l_cycle = l_cycle\n",
    "        \n",
    "        self.token_embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.pos_embed = nn.Embedding(context_length, hidden_size)\n",
    "        self.low = nn.GRUCell(input_size=hidden_size*4, hidden_size=hidden_size*4, device=device,)\n",
    "        self.high = nn.GRUCell(input_size=hidden_size*4, hidden_size=hidden_size*4, device=device)\n",
    "        \n",
    "        # self.low = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device,)\n",
    "        # self.high = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size*4, hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size*2, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        \n",
    "        token_embs = self.token_embed(tokens)\n",
    "        pos_embs = self.pos_embed(torch.arange(0, tokens.shape[-1]).to(tokens.device))\n",
    "        \n",
    "        embs = token_embs+pos_embs\n",
    "        embs = embs.view(tokens.shape[0], -1)\n",
    "        # print(embs.shape)\n",
    "        # hx, cx = torch.zeros((tokens.shape[0],pos_embs.shape[-1])), torch.zeros((tokens.shape[0],pos_embs.shape[-1]))\n",
    "        z_l = torch.zeros((tokens.shape[0],embs.shape[-1]))\n",
    "        # print(z_l.shape)\n",
    "        for i in range(self.h_cycle*self.l_cycle):\n",
    "            z_l = self.low(embs, z_l)\n",
    "            if i%self.h_cycle == 0: \n",
    "                # print(f\"at {i}\")\n",
    "                z_h = self.high(embs, z_l)\n",
    "                z_l = z_h\n",
    "        # print('here')\n",
    "        out = self.mlp(z_h)\n",
    "        return out\n",
    "    \n",
    "\n",
    "model = HRM(32, 8, 4, 8)\n",
    "\n",
    "x = torch.randint(0,8, (1,4))\n",
    "out = model(x)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feabb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=1, embed_dim=512, patch_size=16):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, patch_size, patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.proj(x)\n",
    "        out = out.flatten(2)\n",
    "        return out\n",
    "\n",
    "class HRMVision(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_size,in_channels=4, sequence_length = 16, patch_size=64, embed_dim=16, h_cycle = 4, l_cycle = 8, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.h_cycle = h_cycle\n",
    "        self.l_cycle = l_cycle\n",
    "        self.context_length =  16\n",
    "        self.patchify = PatchEmbedding(in_channels, sequence_length, patch_size)\n",
    "        \n",
    "        # self.token_embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.pos_embed = nn.Embedding(self.context_length, embed_dim)\n",
    "        self.low = nn.GRUCell(input_size=embed_dim*embed_dim, hidden_size=embed_dim*embed_dim, device=device,)\n",
    "        self.high = nn.GRUCell(input_size=embed_dim*embed_dim, hidden_size=embed_dim*embed_dim, device=device)\n",
    "        \n",
    "        # self.low = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device,)\n",
    "        # self.high = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim*embed_dim, embed_dim*embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim*embed_dim, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        token_embs = self.patchify(image)\n",
    "        \n",
    "        pos_embs = self.pos_embed(torch.arange(0, self.context_length).to(image.device))\n",
    "        embs = token_embs+pos_embs\n",
    "        embs = embs.view(image.shape[0], -1)\n",
    "        # hx, cx = torch.zeros((tokens.shape[0],pos_embs.shape[-1])), torch.zeros((tokens.shape[0],pos_embs.shape[-1]))\n",
    "        z_l = torch.zeros((image.shape[0],embs.shape[-1]))\n",
    "        # print(z_l.shape)\n",
    "        for i in range(self.h_cycle*self.l_cycle):\n",
    "            z_l = self.low(embs, z_l)\n",
    "            if i%self.h_cycle == 0: \n",
    "                # print(f\"at {i}\")\n",
    "                z_h = self.high(embs, z_l)\n",
    "                z_l = z_h\n",
    "        # print('here')\n",
    "        out = self.mlp(z_h)\n",
    "        return out\n",
    "\n",
    "model = HRMVision(output_size=10, in_channels=1)\n",
    "\n",
    "x = torch.randn((1,1, 256, 256))\n",
    "out = model(x)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdb5559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of HRMVision(\n",
       "  (patchify): PatchEmbedding(\n",
       "    (proj): Conv2d(1, 16, kernel_size=(64, 64), stride=(64, 64))\n",
       "  )\n",
       "  (pos_embed): Embedding(16, 16)\n",
       "  (low): GRUCell(256, 256)\n",
       "  (high): GRUCell(256, 256)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a48032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearningenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
