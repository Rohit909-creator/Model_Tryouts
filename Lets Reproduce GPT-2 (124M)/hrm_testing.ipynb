{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ff6f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "983f8aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c639ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "resnet = torchvision.models.resnet18()\n",
    "\n",
    "# print(resnet.named_modules)\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=1, embed_dim=512, patch_size=16):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, patch_size, patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.proj(x)\n",
    "        out = out.flatten(2)\n",
    "        return out\n",
    "\n",
    "class HRMVision(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, output_size,in_channels=4, sequence_length = 8, patch_size=6, embed_dim=8, h_cycle = 4, l_cycle = 8, device='cpu', model_name=\"model\", learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.h_cycle = h_cycle\n",
    "        self.l_cycle = l_cycle\n",
    "        self.context_length =  sequence_length\n",
    "        self.patchify = PatchEmbedding(in_channels, sequence_length, patch_size)\n",
    "        \n",
    "        # self.token_embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.pos_embed = nn.Embedding(self.context_length, embed_dim*2)\n",
    "        self.low = nn.GRUCell(input_size=embed_dim*embed_dim*2, hidden_size=embed_dim*embed_dim*2, device=device,)\n",
    "        self.high = nn.GRUCell(input_size=embed_dim*embed_dim*2, hidden_size=embed_dim*embed_dim*2, device=device)\n",
    "        \n",
    "        # self.low = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device,)\n",
    "        # self.high = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim*embed_dim*2, embed_dim*embed_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim*embed_dim*2, output_size)\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        self.gradient_norms = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "        # For convergence speed tracking\n",
    "        self.epoch_train_losses = []\n",
    "        self.epoch_val_losses = []\n",
    "        \n",
    "        # For overfitting analysis\n",
    "        self.train_val_gap = []\n",
    "        # self.acc = pl.metrics.classification.Accuracy(task='multiclass', num_classes = 10)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        # print(f'image: {image.shape}')\n",
    "        token_embs = self.patchify(image)\n",
    "        # print(f'token_embs: {token_embs.shape}')\n",
    "        pos_embs = self.pos_embed(torch.arange(0, self.context_length).to(image.device))\n",
    "        # print(f'pos: {pos_embs.shape}')\n",
    "        embs = token_embs+pos_embs\n",
    "        # print(f'embs: {embs.shape}')\n",
    "        embs = embs.view(image.shape[0], -1)\n",
    "        # print(f'embs: {embs.shape}')\n",
    "        # hx, cx = torch.zeros((tokens.shape[0],pos_embs.shape[-1])), torch.zeros((tokens.shape[0],pos_embs.shape[-1]))\n",
    "        z_l = torch.zeros((image.shape[0],embs.shape[-1])).to(image.device)\n",
    "        # print(z_l.shape)\n",
    "        for i in range(self.h_cycle*self.l_cycle):\n",
    "            z_l = self.low(embs, z_l)\n",
    "            if i%self.h_cycle == 0: \n",
    "                # print(f\"at {i}\")\n",
    "                z_h = self.high(embs, z_l)\n",
    "                z_l = z_h\n",
    "        # print('here')\n",
    "        out = self.mlp(z_h)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        \n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        # Store metrics\n",
    "        self.train_losses.append(loss.item())\n",
    "        self.train_accs.append(acc.item())\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # Calculate gradient norm for gradient flow analysis\n",
    "        total_norm = 0\n",
    "        for p in self.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** (1. / 2)\n",
    "        \n",
    "        self.gradient_norms.append(total_norm)\n",
    "        self.log(\"gradient_norm\", total_norm)\n",
    "        \n",
    "        # Store learning rate\n",
    "        current_lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.learning_rates.append(current_lr)\n",
    "        self.log(\"learning_rate\", current_lr)\n",
    "        \n",
    "        # Calculate epoch averages for convergence analysis\n",
    "        if len(self.train_losses) > 0:\n",
    "            # Get losses from this epoch only\n",
    "            steps_per_epoch = len(self.trainer.train_dataloader)\n",
    "            epoch_start_idx = max(0, len(self.train_losses) - steps_per_epoch)\n",
    "            epoch_train_loss = np.mean(self.train_losses[epoch_start_idx:])\n",
    "            self.epoch_train_losses.append(epoch_train_loss)\n",
    "            \n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        # Get current epoch metrics\n",
    "        val_loss = self.trainer.callback_metrics.get(\"val_loss\", 0)\n",
    "        val_acc = self.trainer.callback_metrics.get(\"val_acc\", 0)\n",
    "        \n",
    "        if isinstance(val_loss, torch.Tensor):\n",
    "            val_loss = val_loss.item()\n",
    "        if isinstance(val_acc, torch.Tensor):\n",
    "            val_acc = val_acc.item()\n",
    "            \n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accs.append(val_acc)\n",
    "        self.epoch_val_losses.append(val_loss)\n",
    "        \n",
    "        # Calculate overfitting gap (train-val performance difference)\n",
    "        if len(self.epoch_train_losses) > 0 and len(self.epoch_val_losses) > 0:\n",
    "            train_loss = self.epoch_train_losses[-1]\n",
    "            val_loss = self.epoch_val_losses[-1]\n",
    "            gap = val_loss - train_loss  # Positive = overfitting\n",
    "            self.train_val_gap.append(gap)\n",
    "            self.log(\"overfitting_gap\", gap)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def save_metrics(self, filepath):\n",
    "        \"\"\"Save all tracked metrics to a JSON file\"\"\"\n",
    "        metrics = {\n",
    "            'model_name': self.model_name,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'train_accs': self.train_accs,\n",
    "            'val_accs': self.val_accs,\n",
    "            'epoch_train_losses': self.epoch_train_losses,\n",
    "            'epoch_val_losses': self.epoch_val_losses,\n",
    "            'gradient_norms': self.gradient_norms,\n",
    "            'learning_rates': self.learning_rates,\n",
    "            'train_val_gap': self.train_val_gap,\n",
    "            'parameter_count': sum(p.numel() for p in self.parameters())\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        \n",
    "        print(f\"Metrics saved to {filepath}\")\n",
    "    \n",
    "    def print_analysis(self):\n",
    "        \"\"\"Print analysis of tracked metrics\"\"\"\n",
    "        if len(self.epoch_train_losses) < 2:\n",
    "            print(\"Not enough epochs for analysis\")\n",
    "            return\n",
    "            \n",
    "        print(f\"\\n=== Analysis for {self.model_name} ===\")\n",
    "        \n",
    "        # Convergence speed\n",
    "        initial_loss = self.epoch_train_losses[0]\n",
    "        final_loss = self.epoch_train_losses[-1]\n",
    "        convergence_rate = (initial_loss - final_loss) / len(self.epoch_train_losses)\n",
    "        print(f\"Convergence rate: {convergence_rate:.6f} loss/epoch\")\n",
    "        \n",
    "        # Overfitting analysis\n",
    "        if len(self.train_val_gap) > 0:\n",
    "            avg_gap = np.mean(self.train_val_gap)\n",
    "            final_gap = self.train_val_gap[-1]\n",
    "            print(f\"Average overfitting gap: {avg_gap:.6f}\")\n",
    "            print(f\"Final overfitting gap: {final_gap:.6f}\")\n",
    "            \n",
    "        # Gradient flow\n",
    "        if len(self.gradient_norms) > 0:\n",
    "            avg_grad_norm = np.mean(self.gradient_norms)\n",
    "            grad_std = np.std(self.gradient_norms)\n",
    "            print(f\"Average gradient norm: {avg_grad_norm:.6f}\")\n",
    "            print(f\"Gradient norm std: {grad_std:.6f}\")\n",
    "            \n",
    "        # Loss landscape smoothness (approximated by loss variance)\n",
    "        train_loss_var = np.var(self.train_losses)\n",
    "        val_loss_var = np.var(self.val_losses) if self.val_losses else 0\n",
    "        print(f\"Training loss variance (smoothness): {train_loss_var:.6f}\")\n",
    "        print(f\"Validation loss variance: {val_loss_var:.6f}\")   \n",
    "     \n",
    "model = HRMVision(output_size=10, in_channels=1)\n",
    "\n",
    "x = torch.randn((1,1, 28, 28))\n",
    "out = model(x)\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "class ResnetSmall(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7,7), stride=(2, 2), padding=(3,3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=64, out_features=10, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "small_model = ResnetSmall()\n",
    "x = torch.randn((1,1,28,28))\n",
    "out = small_model(x)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb339e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ec3977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# --------------------------\n",
    "# 1. Load & preprocess MNIST\n",
    "# --------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))   # Standard MNIST normalization\n",
    "])\n",
    "\n",
    "# Download train data\n",
    "mnist = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
    "\n",
    "# Split into train and validation\n",
    "train_size = int(0.8 * len(mnist))\n",
    "val_size = len(mnist) - train_size\n",
    "mnist_train, mnist_val = random_split(mnist, [train_size, val_size])\n",
    "\n",
    "\n",
    "\n",
    "# mnist_train is already a Subset — we need to look at its .indices\n",
    "original_indices = np.array(mnist_train.indices)\n",
    "targets = mnist.targets.numpy()[original_indices]  # filter targets by the split\n",
    "\n",
    "num_classes = 10\n",
    "samples_per_class = 100\n",
    "selected_indices = []\n",
    "\n",
    "for c in range(num_classes):\n",
    "    class_indices = np.where(targets == c)[0]           # indices within this split\n",
    "    chosen = np.random.choice(class_indices, samples_per_class, replace=False)\n",
    "    selected_indices.extend(chosen)\n",
    "\n",
    "# Now remap to actual dataset indices\n",
    "balanced_indices = original_indices[selected_indices]\n",
    "\n",
    "balanced_subset = Subset(mnist, balanced_indices)\n",
    "\n",
    "train_loader = DataLoader(balanced_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2. Create DataLoaders\n",
    "# --------------------------\n",
    "# train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(mnist_val, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "# Instantiate trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=8,\n",
    "    accelerator='auto',  # Uses GPU if available\n",
    "    devices=1,\n",
    "    logger=True,\n",
    "    log_every_n_steps=50,\n",
    "    check_val_every_n_epoch=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "# trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36fdcf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HRMVision(output_size=10, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6fc3b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | patchify  | PatchEmbedding   | 296    | train\n",
      "1 | pos_embed | Embedding        | 128    | train\n",
      "2 | low       | GRUCell          | 99.1 K | train\n",
      "3 | high      | GRUCell          | 99.1 K | train\n",
      "4 | mlp       | Sequential       | 17.8 K | train\n",
      "5 | loss_fn   | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "216 K     Trainable params\n",
      "0         Non-trainable params\n",
      "216 K     Total params\n",
      "0.865     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 32/32 [00:01<00:00, 19.09it/s, v_num=7, train_loss=0.0485, train_acc=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 32/32 [00:01<00:00, 18.66it/s, v_num=7, train_loss=0.0485, train_acc=1.000]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3137863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to HRMVision_metrics.json\n",
      "\n",
      "=== Analysis for model ===\n",
      "Convergence rate: 0.230247 loss/epoch\n",
      "Average gradient norm: 2.774449\n",
      "Gradient norm std: 1.572824\n",
      "Training loss variance (smoothness): 0.368841\n",
      "Validation loss variance: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_name = \"HRMVision\"\n",
    "model.save_metrics(f\"{model_name}_metrics.json\")\n",
    "model.print_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6abf679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./lightning_logs/version_1/metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aa8e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>739</td>\n",
       "      <td>0.048125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.133682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1479</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2219</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  step  train_loss  val_loss\n",
       "0      0   739    0.048125       NaN\n",
       "1      0   749         NaN  0.133682\n",
       "2      1  1479    0.137428       NaN\n",
       "3      1  1499         NaN  0.095904\n",
       "4      2  2219    0.029386       NaN\n",
       "5      2  2249         NaN  0.096174"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800655c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HRMVision(\n",
       "  (patchify): PatchEmbedding(\n",
       "    (proj): Conv2d(1, 8, kernel_size=(6, 6), stride=(6, 6))\n",
       "  )\n",
       "  (pos_embed): Embedding(8, 16)\n",
       "  (low): GRUCell(128, 128)\n",
       "  (high): GRUCell(128, 128)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets Reproduce GPT-2 (124M)\\lightning_logs\\version_3\\checkpoints\\epoch=7-step=256.ckpt\n",
    "model = HRMVision.load_from_checkpoint(\"./lightning_logs/version_3/checkpoints/epoch=7-step=256.ckpt\", output_size=10, in_channels=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a605c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 4\n",
      "tensor([4])\n"
     ]
    }
   ],
   "source": [
    "print(mnist_val[1][0].shape, mnist_val[1][1])\n",
    "test_input = mnist_val[1][0].unsqueeze(0).to('cpu')\n",
    "# print(test_input.shape)\n",
    "prediction = model(test_input)\n",
    "print(torch.argmax(prediction, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10cc547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [mnist_val[i][1] for i in range(len(mnist_val))]\n",
    "pred_labels = [torch.argmax(model(mnist_val[i][0].unsqueeze(0).to('cpu')),dim=-1).item() for i in range(len(mnist_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e74ed399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89575"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously accuracy was 0.89075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a29baf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 9, 2, 2, 1, 8, 3, 6, 0, 7, 2, 5, 5, 1, 3, 8, 4, 9, 4, 9, 6, 6, 1, 5, 3, 5, 0, 3, 5, 9, 7, 7, 8, 6, 8, 6, 6, 9, 1, 6, 8, 0, 0, 3, 7, 3, 6, 7, 6, 1, 7, 0, 5, 1, 3, 0, 2, 2, 1, 3, 4, 8, 7, 2, 3, 3, 4, 1, 4, 2, 4, 7, 7, 2, 8, 8, 4, 1, 3, 2, 4, 1, 5, 1, 9, 1, 3, 5, 7, 9, 1, 5, 6, 8, 7, 9, 6, 0, 1, 3, 3, 7, 1, 0, 9, 8, 5, 6, 4, 0, 5, 2, 5, 0, 9, 7, 6, 9, 5, 2, 1, 9, 2, 6, 0, 3, 6, 1, 8, 9, 5, 9, 6, 7, 6, 7, 3, 8, 8, 0, 2, 3, 5, 1, 5, 4, 9, 3, 9, 9, 8, 4, 7, 1, 8, 2, 5, 1, 1, 6, 2, 4, 8, 0, 3, 4, 2, 3, 4, 0, 1, 5, 2, 4, 3, 8, 6, 7, 2, 0, 9, 2, 2, 3, 2, 4, 2, 9, 0, 6, 1, 7, 3, 7, 2, 0, 8, 0, 7, 4, 4, 9, 4, 0, 2, 6, 8, 9, 0, 8, 5, 8, 4, 9, 4, 9, 8, 4, 8, 9, 3, 8, 0, 3, 6, 9, 3, 4, 3, 3, 3, 9, 7, 4, 9, 6, 6, 4, 9, 7, 5, 0, 6, 4, 7, 5, 5, 8, 9, 0, 9, 5, 4, 7, 0, 2, 2, 0, 8, 4, 3, 5, 8, 1, 9, 9, 5, 6, 2, 1, 6, 0, 0, 9, 8, 8, 1, 3, 6, 7, 6, 8, 2, 0, 5, 3, 2, 8, 8, 2, 6, 6, 9, 9, 1, 5, 5, 6, 8, 9, 1, 3, 9, 4, 5, 5, 5, 2, 4, 5, 7, 8, 5, 4, 5, 1, 5, 7, 1, 7, 3, 4, 6, 4, 2, 3, 8, 9, 2, 4, 5, 7, 3, 8, 9, 3, 4, 7, 1, 2, 2, 9, 8, 6, 9, 5, 4, 5, 3, 3, 5, 2, 5, 1, 2, 2, 2, 0, 2, 0, 0, 0, 3, 9, 6, 1, 6, 0, 0, 2, 8, 9, 5, 7, 4, 8, 1, 4, 0, 5, 9, 0, 0, 0, 3, 5, 6, 1, 9, 2, 4, 2, 8, 8, 0, 4, 3, 5, 6, 9, 8, 7, 1, 9, 0, 7, 8, 0, 1, 4, 6, 2, 2, 4, 6, 5, 7, 3, 9, 7, 1, 7, 6, 1, 1, 5, 8, 4, 9, 9, 5, 8, 4, 8, 7, 0, 1, 4, 7, 2, 1, 3, 6, 7, 8, 3, 9, 0, 5, 0, 2, 0, 4, 4, 5, 7, 5, 1, 6, 3, 3, 1, 7, 3, 7, 0, 3, 6, 5, 6, 0, 5, 2, 7, 7, 8, 0, 4, 4, 4, 3, 2, 3, 2, 1, 0, 5, 2, 6, 3, 5, 2, 2, 6, 5, 8, 6, 6, 5, 4, 8, 2, 5, 4, 7, 4, 3, 9, 4, 7, 5, 5, 3, 0, 1, 4, 1, 2, 4, 0, 8, 0, 7, 9, 5, 1, 0, 4, 8, 3, 2, 0, 6, 0, 2, 0, 1, 7, 2, 1, 0, 7, 8, 3, 3, 3, 1, 7, 7, 7, 3, 7, 6, 5, 8, 2, 1, 9, 9, 8, 4, 3, 3, 2, 1, 3, 5, 7, 7, 0, 5, 4, 6, 5, 3, 1, 7, 1, 5, 2, 1, 6, 8, 9, 9, 2, 1, 8, 2, 0, 1, 2, 2, 8, 7, 4, 9, 7, 3, 6, 7, 9, 3, 4, 9, 8, 8, 7, 6, 3, 4, 2, 1, 6, 4, 4, 2, 5, 9, 4, 0, 1, 7, 9, 7, 8, 0, 3, 5, 7, 8, 7, 1, 3, 5, 0, 6, 3, 7, 3, 6, 4, 1, 6, 6, 7, 3, 7, 5, 6, 8, 7, 8, 2, 2, 1, 0, 6, 0, 7, 4, 5, 7, 8, 1, 8, 6, 0, 0, 9, 8, 1, 7, 1, 7, 8, 0, 1, 6, 4, 3, 1, 1, 8, 0, 7, 0, 0, 1, 8, 4, 9, 5, 5, 7, 1, 6, 9, 0, 1, 7, 1, 7, 8, 6, 8, 1, 2, 3, 0, 0, 9, 0, 1, 9, 9, 2, 6, 9, 4, 6, 2, 8, 1, 8, 8, 2, 2, 5, 5, 8, 3, 9, 1, 2, 7, 8, 9, 2, 4, 1, 6, 7, 9, 6, 2, 5, 0, 2, 1, 9, 1, 6, 8, 6, 3, 7, 3, 7, 9, 7, 5, 2, 9, 4, 1, 6, 9, 7, 7, 3, 0, 2, 5, 6, 5, 4, 2, 0, 5, 4, 8, 5, 7, 0, 6, 9, 7, 1, 2, 2, 1, 6, 4, 6, 5, 6, 5, 5, 3, 2, 6, 8, 7, 5, 4, 7, 5, 4, 8, 3, 3, 7, 2, 0, 2, 5, 7, 8, 6, 8, 3, 1, 1, 6, 7, 8, 0, 5, 6, 3, 3, 5, 0, 8, 1, 8, 1, 2, 0, 8, 3, 1, 9, 9, 9, 4, 1, 1, 0, 3, 8, 1, 8, 9, 0, 2, 4, 5, 7, 9, 9, 1, 4, 8, 0, 4, 0, 3, 3, 1, 7, 3, 4, 8, 7, 6, 7, 1, 7, 7, 9, 7, 4, 1, 6, 8, 8, 6, 3, 9, 8, 7, 9, 7, 7, 8, 7, 7, 7, 2, 5, 3, 3, 0, 9, 5, 5, 0, 7, 9, 3, 3, 4, 6, 5, 0, 5, 7, 9, 6, 7, 2, 7, 4, 0, 3, 0, 8, 0, 4, 3, 4, 9, 1, 8, 5, 1, 3, 3, 2, 1, 4, 3, 3, 6, 7, 5, 1, 3, 7, 3, 3, 2, 7, 0, 3, 1, 6, 4, 8, 1, 8, 5, 5, 0, 5, 8, 6, 3, 0, 6, 3, 6, 9, 4, 1, 6, 1, 0, 6, 8, 0, 1, 2, 8, 4, 1, 2, 2, 8, 2, 3, 5, 9, 0, 4, 2, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for i in range(1000):\n",
    "    labels.append(mnist_train[i][1])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "368095b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 98, 1: 106, 2: 98, 3: 106, 4: 92, 5: 101, 6: 94, 7: 110, 8: 103, 9: 92}\n"
     ]
    }
   ],
   "source": [
    "count_dict = dict()\n",
    "for i in range(10):\n",
    "    count_dict[i] = labels.count(i)\n",
    "print(count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd104126",
   "metadata": {},
   "source": [
    "# Tranformers Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ee1662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rohit Francis\\Desktop\\Codes\\AI_Projects\\Model_Tryouts\\deeplearningenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Create a config class\n",
    "class HRMConfig(PretrainedConfig):\n",
    "    model_type = \"hrm\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels=1, \n",
    "                 embed_dim=16, \n",
    "                 sequence_length=16, \n",
    "                 output_size=10, \n",
    "                 h_cycle=4, \n",
    "                 l_cycle=8,\n",
    "                 patch_size=16, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_size = in_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_size = output_size\n",
    "        self.h_cycle = h_cycle\n",
    "        self.l_cycle = l_cycle\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 2. Wrap your model inside a PreTrainedModel\n",
    "class HRMForClassification(PreTrainedModel):\n",
    "    config_class = HRMConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.h_cycle = config.h_cycle\n",
    "        self.l_cycle = config.l_cycle\n",
    "        self.context_length =  16\n",
    "        self.patchify = PatchEmbedding(config.in_channels, config.sequence_length, config.patch_size)\n",
    "        \n",
    "        # self.token_embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.pos_embed = nn.Embedding(self.context_length, config.embed_dim)\n",
    "        self.low = nn.GRUCell(input_size=config.embed_dim*config.embed_dim, hidden_size=config.embed_dim*config.embed_dim, device=config.device,)\n",
    "        self.high = nn.GRUCell(input_size=config.embed_dim*config.embed_dim, hidden_size=config.embed_dim*config.embed_dim, device=config.device)\n",
    "        \n",
    "        # self.low = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device,)\n",
    "        # self.high = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size, device=device)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.embed_dim*config.embed_dim, config.embed_dim*config.embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.embed_dim*config.embed_dim, config.output_size)\n",
    "        )\n",
    "\n",
    "        # Initialize weights the Transformers way\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids=None, labels=None, **kwargs):\n",
    "        tokens = input_ids\n",
    "        token_embs = self.token_embed(tokens)\n",
    "        pos_embs = self.pos_embed(\n",
    "            torch.arange(0, tokens.shape[-1], device=tokens.device)\n",
    "        )\n",
    "        embs = token_embs + pos_embs\n",
    "        embs = embs.view(tokens.shape[0], -1)\n",
    "\n",
    "        z_l = torch.zeros((tokens.shape[0], embs.shape[-1]), device=tokens.device)\n",
    "        for i in range(self.h_cycle * self.l_cycle):\n",
    "            z_l = self.low(embs, z_l)\n",
    "            if i % self.h_cycle == 0:\n",
    "                z_h = self.high(embs, z_l)\n",
    "                z_l = z_h\n",
    "        logits = self.mlp(z_h)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.config.output_size), labels.view(-1))\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a34ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12121303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearningenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
